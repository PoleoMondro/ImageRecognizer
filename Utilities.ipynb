{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFile(fileName):\n",
    "    array = np.load(fileName)\n",
    "    \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(inTainSet, atPosition):\n",
    "    img = inTainSet[atPosition,:,:,:]/255.0\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(trainingSet):\n",
    "    size = trainingSet.shape[0]*trainingSet.shape[1]*trainingSet.shape[2]*trainingSet.shape[3] #total number of pixel in the training set\n",
    "    accum = 0 #variable to sum all the values\n",
    "    \n",
    "    for im in range(0,trainingSet.shape[0]): #pass throught all images\n",
    "        for row in range(0,trainingSet.shape[1]): #pass throught all rows in the current image\n",
    "            for col in range(0,trainingSet.shape[2]):  #pass throught all column in the current row of the current image \n",
    "                for channel in range(0,trainingSet.shape[3]): #pass throught all channel in the current column of the current row of the current image\n",
    "                    accum += trainingSet[im,row,col,channel]\n",
    "                    \n",
    "    mean = accum / (size) #calculate the mean pixel value of the training set\n",
    "    \n",
    "    for im in range(0,trainingSet.shape[0]):\n",
    "        for row in range(0,trainingSet.shape[1]): \n",
    "            for col in range(0,trainingSet.shape[2]):   \n",
    "                for channel in range(0,trainingSet.shape[3]):\n",
    "                    trainingSet[im,row,col,channel] = (trainingSet[im,row,col,channel] - mean)/mean # substract the mean value to all pixel of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (number of examples, img width, image height, number of channel)\n",
    "    Y -- true \"label\" vector (containing int number of the class value), of shape (number of examples, 1)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation, :, :, :]\n",
    "    shuffled_Y = Y[permutation, :].reshape((m, Y.shape[1]))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size, :, :, :]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size, :]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m, :, :, :]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m, :]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convolutional_layer(input,\n",
    "               num_input_channels, \n",
    "               conv_filter_size,        \n",
    "               num_filters,\n",
    "               padding,\n",
    "               strides,\n",
    "               layer_number):  \n",
    "    \"\"\"\n",
    "    TF's conv2d function calculates convolutions in batches and uses a slightly different format. \n",
    "    For an input it is [batch, in_height, in_width, in_channels] \n",
    "    For the filter it is [filter_height, filter_width, in_channels, out_channels]\n",
    "    padding: 'SAME' or 'VALID'\n",
    "    strides: [data, height, width, channel], usually [1, 2, 2, 1] to reduce data size per 2\n",
    "    \"\"\"\n",
    "    \n",
    "    ## We shall define the weights that will be trained using create_weights function.\n",
    "    weights = create_weights(name='Wconv_'+layer_number, shape=[conv_filter_size, conv_filter_size, num_input_channels, num_filters])\n",
    "    ## We create biases using the create_biases function. These are also trained.\n",
    "    biases = create_biases(name='Bconv_'+layer_number, size=num_filters)\n",
    " \n",
    "    ## Creating the convolutional layer\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                     filter=weights,\n",
    "                     strides=strides,\n",
    "                     padding=padding)\n",
    " \n",
    "    layer += biases\n",
    " \n",
    "    return layer, weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

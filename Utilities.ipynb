{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFile(fileName):\n",
    "    array = np.load(fileName)\n",
    "    \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(inTainSet, atPosition):\n",
    "    img = inTainSet[atPosition,:,:,:]/255.0\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(trainingSet):\n",
    "    size = trainingSet.shape[0]*trainingSet.shape[1]*trainingSet.shape[2]*trainingSet.shape[3] #total number of pixel in the training set\n",
    "    accum = 0 #variable to sum all the values\n",
    "    \n",
    "    for im in range(0,trainingSet.shape[0]): #pass throught all images\n",
    "        for row in range(0,trainingSet.shape[1]): #pass throught all rows in the current image\n",
    "            for col in range(0,trainingSet.shape[2]):  #pass throught all column in the current row of the current image \n",
    "                for channel in range(0,trainingSet.shape[3]): #pass throught all channel in the current column of the current row of the current image\n",
    "                    accum += trainingSet[im,row,col,channel]\n",
    "                    \n",
    "    mean = accum / (size) #calculate the mean pixel value of the training set\n",
    "    \n",
    "    for im in range(0,trainingSet.shape[0]):\n",
    "        for row in range(0,trainingSet.shape[1]): \n",
    "            for col in range(0,trainingSet.shape[2]):   \n",
    "                for channel in range(0,trainingSet.shape[3]):\n",
    "                    trainingSet[im,row,col,channel] = (trainingSet[im,row,col,channel] - mean)/mean # substract the mean value to all pixel of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (number of examples, img width, image height, number of channel)\n",
    "    Y -- true \"label\" vector (containing int number of the class value), of shape (number of examples, 1)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation, :, :, :]\n",
    "    shuffled_Y = Y[permutation, :].reshape((m, Y.shape[1]))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size, :, :, :]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size, :]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m, :, :, :]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m, :]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convolutional_layer(input,\n",
    "               num_input_channels, \n",
    "               conv_filter_size,        \n",
    "               num_filters,\n",
    "               padding,\n",
    "               strides,\n",
    "               layer_number, use_bias = True):  \n",
    "    \"\"\"\n",
    "    TF's conv2d function calculates convolutions in batches and uses a slightly different format. \n",
    "    For an input it is [batch, in_height, in_width, in_channels] \n",
    "    For the filter it is [filter_height, filter_width, in_channels, out_channels]\n",
    "    padding: 'SAME' or 'VALID'\n",
    "    strides: [data, height, width, channel], usually [1, 2, 2, 1] to reduce data size per 2\n",
    "    \"\"\"\n",
    "    \n",
    "    ## We shall define the weights that will be trained using create_weights function.\n",
    "    weights = create_weights(name='Wconv_'+layer_number, shape=[conv_filter_size, conv_filter_size, num_input_channels, num_filters])\n",
    "    ## We create biases using the create_biases function. These are also trained.\n",
    "    biases = create_biases(name='Bconv_'+layer_number, size=num_filters)\n",
    " \n",
    "    ## Creating the convolutional layer\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                     filter=weights,\n",
    "                     strides=strides,\n",
    "                     padding=padding)\n",
    " \n",
    "    if use_bias:\n",
    "        layer += biases\n",
    " \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_weights(shape, name, initializer= tf.contrib.layers.xavier_initializer()):\n",
    "    return tf.get_variable(name=name, shape=shape, initializer= initializer)\n",
    " \n",
    "def create_biases(size, name, initializer= tf.zeros_initializer()):\n",
    "    return tf.get_variable(name=name, shape=[size], initializer= initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(img_size, num_channels, num_classes):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 199, so -> 200)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - Use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "    \n",
    "    X = tf.placeholder(name='X', dtype=tf.float32, shape=[None, img_size,img_size,num_channels])\n",
    "    Y = tf.placeholder(name='Y', dtype=tf.int32, shape=[None, num_classes])\n",
    "\n",
    "    return X, Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet ARCHITECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implement the Inception architecture for image recognition using CNN.\n",
    "You can find the paper describing this architecture by following the link:\n",
    "https://arxiv.org/pdf/1409.4842.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here is the global architecture of a Inception network : **\n",
    "<img src=\"images/inception_network.png\" style=\"width:1984px;height:584px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Utilities.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Residual layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here is the architecture of an Inception unit block : **\n",
    "<img src=\"images/inception_block.png\" style=\"width:664px;height:354px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_1x1_convolution(input,\n",
    "               num_input_channels,        \n",
    "               num_filters,\n",
    "               padding,\n",
    "               strides,\n",
    "               layer_number, use_bias = True):\n",
    "    return create_convolutional_layer(input, num_input_channels=num_input_channels, num_filters= num_filters, conv_filter_size=1, padding= padding, strides= strides, layer_number=layer_number, use_bias= use_bias)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3x3_convolution(input,\n",
    "               num_input_channels,        \n",
    "               num_filters,\n",
    "               padding,\n",
    "               strides,\n",
    "               layer_number, use_bias = True):\n",
    "    return create_convolutional_layer(input, num_input_channels=num_input_channels, num_filters= num_filters, conv_filter_size=3, padding= padding, strides= strides, layer_number=layer_number, use_bias= use_bias)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_5x5_convolution(input,\n",
    "               num_input_channels,        \n",
    "               num_filters,\n",
    "               padding,\n",
    "               strides,\n",
    "               layer_number, use_bias = True):\n",
    "    return create_convolutional_layer(input, num_input_channels=num_input_channels, num_filters= num_filters, conv_filter_size=5, padding= padding, strides= strides, layer_number=layer_number, use_bias= use_bias)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_max_pooling_layer(input, parameters):  \n",
    "\n",
    "    ksize = [1, 3, 3, 1] #example [1, 2, 2, 1] corresponding [batch_size, img_size, img_size, number of channel]\n",
    "    strides = parameters['strides_pooling'] #example [1, 2, 2, 1] corresponding [batch_size, img_size, img_size, number of channel]\n",
    "    padding = parameters['padding'] #example 'SAME' or 'VALID'\n",
    "    \n",
    "    ## \"Max-pooling is performed over a 2x2 pixel window, with stride 2\".  \n",
    "    layer = tf.nn.max_pool(value=input,\n",
    "                            ksize=ksize,\n",
    "                            strides=strides,\n",
    "                            padding=padding)\n",
    " \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_activation_layer(input):  \n",
    "    ## \"All hidden layers are equipped with the rectification non-linearity\"\n",
    "    layer = tf.nn.relu(input)\n",
    " \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate(input1, input2, input3, input4):\n",
    "    return np.concatenate((input1, input2, input3, input4), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inception_module(input):\n",
    "    conv11 = create1x1convolution(input=input)\n",
    "    act11 = create_activation_layer(conv11)\n",
    "    \n",
    "    conv21 = create1x1convolution(input=input)\n",
    "    act21 = create_activation_layer(conv21)\n",
    "    conv22 = create3x3convolution(input=conv21)\n",
    "    act22 = create_activation_layer(conv22)\n",
    "    \n",
    "    conv31 = create1x1convolution(input=input)\n",
    "    act31 = create_activation_layer(conv31)\n",
    "    conv32 = create5x5convolution(input=conv31)\n",
    "    act32 = create_activation_layer(conv32)\n",
    "    \n",
    "    pool41 = create_max_pooling_layer(input=input)\n",
    "    act41 = create_activation_layer(conv41)\n",
    "    conv42 = create1x1convolution(input=pool41)\n",
    "    act42 = create_activation_layer(conv42)\n",
    "    \n",
    "    return concatenate(act12, act22, act32, act42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fully_connected_layer(input, num_input_channels, num_output_channel, layer_number):\n",
    "        \n",
    "    ## We shall define the weights that will be trained using create_weights function.\n",
    "    weights = create_weights(name='Wfc_'+layer_number, shape=[input.shape[1], input.shape[2], num_input_channels, num_output_channel])\n",
    "    ## We create biases using the create_biases function. These are also trained.\n",
    "    biases = create_biases(name='Bfc_'+layer_number, size=num_output_channel)\n",
    "    \n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                     filter=weights,\n",
    "                     strides=[1, 1, 1, 1],\n",
    "                    padding= 'VALID')\n",
    "    \n",
    "    layer += layer + biases\n",
    "    \n",
    "    return layer, weights, biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_softmax_layer(networkOutput, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Output -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as output\n",
    "    \n",
    "    Returns:\n",
    "    the coss entropy\n",
    "    \"\"\"\n",
    "    \n",
    "    return tf.nn.softmax_cross_entropy_with_logits_v2(logits= networkOutput, labels= Y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(softmaxOutput):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    softmaxOutput -- output of the softmax layer\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    cost = tf.reduce_mean(softmaxOutput)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_average_pooling_layer(input, parameters):  \n",
    "\n",
    "    ksize = parameters['ksize'] #example [1, 2, 2, 1] corresponding [batch_size, img_size, img_size, number of channel]\n",
    "    strides = parameters['strides_pooling'] #example [1, 2, 2, 1] corresponding [batch_size, img_size, img_size, number of channel]\n",
    "    padding = parameters['padding'] #example 'SAME' or 'VALID'\n",
    "    \n",
    "    ## \"Max-pooling is performed over a 2x2 pixel window, with stride 2\".  \n",
    "    layer = tf.nn.avg_pool(input=input, ksize=ksize, padding=padding, strides=strides)\n",
    " \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configuration_Test(X, architecture):\n",
    "    \n",
    "    parameters = {}\n",
    "    \n",
    "    parameters_inception1 = architecture['parameters_inception']\n",
    "    \n",
    "    parameters_max_pooling = architecture['parameters_max_pooling']\n",
    "    parameters_avg_pooling = architecture['parameters_avg_pooling']\n",
    "    \n",
    "    num_output_class = architecture['num_output_class']\n",
    "    \n",
    "    size_pooling1 = [1, 2, 2, 1] \n",
    "    strides_pooling1 = [1, 2, 2, 1]\n",
    "    padding1 = 'SAME'\n",
    "\n",
    "    parameters_pooling1 = {\n",
    "                            'size_pooling': size_pooling1,\n",
    "                            'strides_pooling': strides_pooling1,\n",
    "                            'padding': padding1\n",
    "                            }\n",
    "    \n",
    "    layer_conv1 = create_convolutional_layer(input= X,conv_filter_size=9, num_input_channels= X.shape[3], num_filters= 64,padding= 'VALID',strides= [1,1,1,1], layer_number= 'conv1')\n",
    "    \n",
    "    layer_bn1 = tf.layers.batch_normalization(layer_conv1)\n",
    "    layer_act1 = create_activation_layer(layer_bn1)\n",
    "    \n",
    "    layer_inception3a = create_inception_module(input=layer_act1)\n",
    "    layer_inception3b = create_inception_module(input=layer_inception3a)\n",
    "    \n",
    "    layer_maxpool1 = create_max_pooling_layer(input=layer_inception3b, parameters= parameters_pooling)\n",
    "    \n",
    "    layer_inception4a = create_inception_module(input=layer_maxpool1)\n",
    "    layer_inception4b = create_inception_module(input=layer_inception4a)\n",
    "    layer_inception4c = create_inception_module(input=layer_inception4b)\n",
    "    layer_inception4d = create_inception_module(input=layer_inception4c)\n",
    "    layer_inception4e = create_inception_module(input=layer_inception4d)\n",
    "    \n",
    "    layer_maxpool2 = create_max_pooling_layer(input=layer_inception4e, parameters= parameters_pooling)\n",
    "    \n",
    "    layer_inception5a = create_inception_module(input=layer_maxpool2)\n",
    "    layer_inception5b = create_inception_module(input=layer_inception5a)\n",
    "    \n",
    "    layer_avg = create_average_pooling_layer(input=layer_inception5b, parameters=parameters_avg_pooling) # Average Pooling\n",
    "    layer_dropout = tf.layers.dropout(inputs=layer_avg, rate=0.7)\n",
    "    #layer_fc1 = create_fully_connected_layer(input=layer_gad, num_input_channels=layer_gad.shape[3], num_output_channel=num_output_class, layer_number='fc1')\n",
    "    #layer_maxpool1 = create_pooling_layer(input=layer_convRes4, parameters=parameters_pooling1)\n",
    "    # FLATTEN\n",
    "    P2 = tf.contrib.layers.flatten(layer_dropout)\n",
    "    # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
    "    # 6 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "    layer_fc1 = tf.contrib.layers.fully_connected(P2, num_outputs=4, activation_fn=None)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return layer_fc1, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallele_exit(input):\n",
    "    layer_avg = create_average_pooling_layer(input=input, parameters=parameters_avg_pooling)\n",
    "    layer_conv1 = create1x1convolution(input=layer_avg, num_filters=128, num_input_channels=layer_avg.shape[3], layer_number='conv_exit_1')\n",
    "    layer_act1 = create_activation_layer(input=layer_conv1)\n",
    "    \n",
    "    layer_fc1 = create_fully_connected_layer(input=layer_act1, num_input_channels=layer_act1.shape[3], num_output_channel=1024, layer_number='fc1_exit1')\n",
    "    layer_dropout = tf.layers.dropout(inputs=layer_fc1, rate=0.7)\n",
    "    layer_fc2 = create_fully_connected_layer(input=layer_dropout, num_input_channels=layer_dropout.shape[3], num_output_channel=4, layer_number='fc2_exit1')\n",
    "    \n",
    "    return layer_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.01, configuration= 'configuration_A',\n",
    "          num_epochs = 100, minibatch_size = 32, momentum = 0.9, use_nesterov = False, print_cost = True, beta = 0.001):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    (m, n_w, n_h, n_c) = X_train.shape                # (m : number of examples in the train set, n_w: image width, n_h: image height, n_c: number of image channel)\n",
    "    n_y = Y_train.shape[1]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders\n",
    "    X, Y = create_placeholders(img_size=n_w, num_channels=n_c, num_classes=n_y)\n",
    "    \n",
    "    # Forward propagation\n",
    "    if configuration == 'configuration_Test':\n",
    "        architecture = get_parameters_configurationTest()\n",
    "        configuration_output, parameters = configuration_Test(X=X,architecture=architecture)\n",
    "            \n",
    "    #Create softmax layer\n",
    "    softmax_layer = create_softmax_layer(Y=Y, networkOutput=configuration_output)\n",
    "    \n",
    "    # Cost function\n",
    "    cost = compute_cost(softmaxOutput=softmax_layer)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer.\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=momentum, use_nesterov=use_nesterov).minimize(cost)\n",
    "    #gvs = optimizer.compute_gradients(cost)\n",
    "    #capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "    #train_op = optimizer.apply_gradients(capped_gvs)\n",
    "    \n",
    "    # Initialize variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "                # Run the session: execute \"optimizer\" and \"cost\"\n",
    "                _, minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "               \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "                #print(minibatch_cost)\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.reshape(tf.argmax(configuration_output, -1), [-1])\n",
    "        true_label = tf.argmax(Y, 1)\n",
    "        correct_prediction = tf.equal(predict_op, true_label)\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "        \n",
    "        return train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(X_train=X_train, Y_train=Y_tain, X_test=X_test, Y_test=Y_test, configuration='configuration_Test', momentum= 0.9, num_epochs=50,learning_rate=0.01, minibatch_size=128, use_nesterov=False, print_cost= True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
